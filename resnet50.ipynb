{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.initializers import glorot_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv(r'C:\\Users\\User\\Desktop\\jiko\\dog-breed-identification\\labels.csv')\n",
    "\n",
    "breed_list = ['beagle', 'chihuahua', 'doberman','french_bulldog', 'golden_retriever', 'malamute', 'pug', 'saint_bernard', 'scottish_deerhound','tibetan_mastiff']\n",
    "\n",
    "entries = data.loc[data['breed'].isin(breed_list)].index\n",
    "\n",
    "\n",
    "train_df = pd.DataFrame(columns=['id','breed'])\n",
    "\n",
    "train_df['id'] = \"\"\n",
    "train_df['breed'] = \"\"\n",
    "\n",
    "for i in range(0, len(entries)):\n",
    "    \n",
    "    train_df.at[i,'id']= data['id'].iloc[entries[i]]\n",
    "\n",
    "    train_df.at[i,'breed']= data['breed'].iloc[entries[i]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_dir = r\"C:\\Users\\User\\Desktop\\jiko\\dog-breed-identification\\train\"\n",
    "\n",
    "all_images = []\n",
    "for i in range(0, len(train_df)) :\n",
    "\n",
    "    image_ = train_df['id'].loc[i] + '.jpg'\n",
    "\n",
    "    train_data_path = os.path.join(train_img_dir, image_)\n",
    "\n",
    "    train_files = glob.glob(train_data_path)\n",
    "\n",
    "\n",
    "    for f1 in train_files:\n",
    "        img = cv2.imread(f1)\n",
    "        img = cv2.resize(img, (224,224))\n",
    "        all_images.append(img)\n",
    "\n",
    "x_train = np.array(all_images)\n",
    "print(\"Shape of training_data: \", x_train.shape, '\\n', \"shape of testing_data: \", x_train.dtype, '\\n')\n",
    "\n",
    "train_set = x_train.astype('float32')\n",
    "\n",
    "'''\n",
    "Labelizing labels.\n",
    "'''\n",
    "breed_count = train_df['breed'].value_counts()\n",
    "print(\"breed_count is: \", breed_count, '\\n')\n",
    "\n",
    "y = train_df['breed'][0: :].values\n",
    "\n",
    "target_ = LabelEncoder()\n",
    "y = target_.fit_transform(y)\n",
    "\n",
    "y = y.reshape(-1, 1)\n",
    "onehotencoder = OneHotEncoder(sparse = False)\n",
    "y_train = onehotencoder.fit_transform(y)\n",
    "\n",
    "\n",
    "'''\n",
    "Shuffling the data.\n",
    "'''\n",
    "train_set, y_train = shuffle(train_set, y_train, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Building the identity block.\n",
    "'''\n",
    "def identity_block(x, kernel_s, filters):\n",
    "\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    x_original = x\n",
    "\n",
    "    #1st layer\n",
    "    x = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1, 1), padding = 'valid')(x)\n",
    "    x = BatchNormalization(axis = 3)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    #2nd layer\n",
    "    x = Conv2D(filters = F2, kernel_size = (kernel_s, kernel_s), strides = (1, 1), padding = 'same')(x)\n",
    "    x = BatchNormalization(axis = 3)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    #3rd layer\n",
    "    x = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1, 1), padding = 'valid')(x)\n",
    "    x = BatchNormalization(axis = 3)(x)\n",
    "\n",
    "    x = Add()([x, x_original])\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Building convolution blocks\n",
    "'''\n",
    "def convolution_block(x, kernel_s, filters, stride_ = 2):\n",
    "\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    x_original = x\n",
    "\n",
    "    #1st layer\n",
    "    x = Conv2D(F1, (1, 1), strides = (stride_, stride_))(x)\n",
    "    x = BatchNormalization(axis = 3)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    #2nd layer\n",
    "    x = Conv2D(filters = F2, kernel_size = (kernel_s, kernel_s), strides = (1, 1), padding = 'same')(x)\n",
    "    x = BatchNormalization(axis = 3)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    #3rd layer\n",
    "    x = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1, 1), padding = 'valid')(x)\n",
    "    x = BatchNormalization(axis = 3)(x)\n",
    "\n",
    "    x_original = Conv2D(filters = F3, kernel_size = (1, 1), strides = (stride_, stride_), padding = 'valid')(x_original)\n",
    "    x_original = BatchNormalization(axis = 3)(x_original)\n",
    "\n",
    "\n",
    "    x = Add()([x, x_original])\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Building Resnet50.\n",
    "'''\n",
    "def Resnet(input_shape = (224, 224, 3), classes = y_train.shape[1]):\n",
    "\n",
    "    x_ = Input(input_shape)\n",
    "\n",
    "    x = ZeroPadding2D((3, 3))(x_)\n",
    "\n",
    "    #1st stage\n",
    "    x = Conv2D(64, (7, 7), strides= (2, 2))(x)\n",
    "    x = BatchNormalization(axis= 3)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides= (2, 2))(x)\n",
    "\n",
    "    #stage 2\n",
    "    x = convolution_block(x, kernel_s=3, filters=[64,64,256], stride_ =1)\n",
    "\n",
    "    x = identity_block(x, 3, [64, 64, 256])\n",
    "\n",
    "    x = identity_block(x, 3, [64, 64, 256])\n",
    "\n",
    "    #stage 3\n",
    "    x = convolution_block(x, kernel_s=3, filters=[128,128,512], stride_ =2)\n",
    "    x = identity_block(x, 3, [128,128,512])\n",
    "    x = identity_block(x, 3, [128,128,512])\n",
    "    x = identity_block(x, 3, [128,128,512])\n",
    "\n",
    "    #stage 4\n",
    "    x = convolution_block(x, kernel_s=3, filters=[256,256,1024], stride_ =2)\n",
    "    x = identity_block(x, 3, [256,256,1024])\n",
    "    x = identity_block(x, 3, [256,256,1024])\n",
    "    x = identity_block(x, 3, [256,256,1024])\n",
    "    x = identity_block(x, 3, [256,256,1024])\n",
    "    x = identity_block(x, 3, [256,256,1024])\n",
    "\n",
    "    #stage 5\n",
    "    x = convolution_block(x, kernel_s=3, filters=[512,512,2048], stride_ =2)\n",
    "    x = identity_block(x, 3, [512,512,2048])\n",
    "    x = identity_block(x, 3, [512,512,2048])\n",
    "\n",
    "    #averagepool\n",
    "    x = AveragePooling2D((2,2), name = \"avg_pool\")(x)\n",
    "\n",
    "    #output layer\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(classes, activation='softmax', name= 'fully_connected_layer', kernel_initializer= glorot_uniform(seed=0))(x)\n",
    "\n",
    "    model = Model(inputs = x_ , outputs = x, name = 'Resnet')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Running the model using the train features and train labels. Saving the trained model into drive location.\n",
    "kindly change the drive location as per choice.\n",
    "'''\n",
    "model = Resnet(input_shape = (224, 224, 3), classes = y_train.shape[1])\n",
    "model.compile(optimizer= 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "model.fit(train_set, y_train, epochs = 100, batch_size = 32) #running fro 100 epochs. Can run as per need.\n",
    "\n",
    "model.save(r\"C:\\Users\\User\\Desktop\\jiko\\resnet50\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Testing the model with unseen images. Labels are not been provided in the given link in assignment. Hence, for calculating confussion matrix is not possible. \n",
    "'''\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import keras\n",
    "\n",
    "\n",
    "def load_test_images(folder):\n",
    "\n",
    "    images = []\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for file_ in os.listdir(folder):\n",
    "\n",
    "\n",
    "        img = cv2.imread( os.path.join(folder, file_))\n",
    "\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (224,224))\n",
    "            images.append(img)\n",
    "\n",
    "        count = count + 1\n",
    "\n",
    "        if count <= 400:\n",
    "\n",
    "            continue\n",
    "\n",
    "        else:\n",
    "\n",
    "            break\n",
    "\n",
    "\n",
    "    x_test = np.array(images, dtype='float32')\n",
    "    print(\"Test data shape: \", x_test.shape)\n",
    "\n",
    "    return x_test\n",
    "\n",
    "\n",
    "\n",
    "def prediction(array_):\n",
    "\n",
    "    train_df = pd.read_csv(r'C:\\Users\\User\\Desktop\\jiko\\dog-breed-identification\\labels.csv')\n",
    "\n",
    "    '''\n",
    "    Labelizing labels.\n",
    "    '''\n",
    "    y = train_df['breed'][0: :].values\n",
    "\n",
    "    target_ = LabelEncoder()\n",
    "\n",
    "    y = target_.fit_transform(y)\n",
    "\n",
    "    labels_ = list(target_.classes_)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "        Prediction\n",
    "    '''\n",
    "    model = keras.models.load_model(r\"C:\\Users\\User\\Desktop\\jiko\\resnet_50\")\n",
    "\n",
    "    predictions = model.predict(array_)\n",
    "\n",
    "    max_prob = np.argmax(predictions,axis=1)\n",
    "\n",
    "    list_ = {'Score': predictions[0][max_prob[0]], 'label_name': labels_[max_prob[0]] }\n",
    "\n",
    "    return list_\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    test_img_dir = r\"C:\\Users\\User\\Desktop\\jiko\\dog-breed-identification\\test\"\n",
    "\n",
    "\n",
    "    test_data = load_test_images(test_img_dir)\n",
    "\n",
    "    predictions = prediction(test_data)\n",
    "\n",
    "    print(predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
